{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6b274b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#atac\n",
    "#url = 'https://www.encodeproject.org/search/?type=Experiment&control_type!=*&status=released&perturbed=false&assay_slims=DNA+accessibility&assay_title=ATAC-seq&replicates.library.biosample.donor.organism.scientific_name=Homo+sapiens&limit=all'\n",
    "#dnase\n",
    "url = 'https://www.encodeproject.org/search/?searchTerm=Dnase-seq&type=Experiment&assay_slims=DNA+accessibility&assay_title=DNase-seq&replicates.library.biosample.donor.organism.scientific_name=Homo+sapiens&assembly=GRCh38&lab.title=John+Stamatoyannopoulos%2C+UW&limit=all'\n",
    "\n",
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "encode_auth = ('ZSHBMR5J',  'pk7hvh3i4q4mcchg')\n",
    "HEADERS = {'accept': 'application/json'}\n",
    "dintype=\"dnase_new\"\n",
    "\n",
    "json_results = requests.get(url, headers=HEADERS, \n",
    "                            auth=encode_auth).json()\n",
    "\n",
    "experiments = [results['accession'] for results in json_results['@graph']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58fed16a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1366"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e09fa72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#json_results  \n",
    "#experiments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "315cbca9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "        \n",
    "encode_auth = ('ZSHBMR5J',  'pk7hvh3i4q4mcchg')\n",
    "HEADERS = {'accept': 'application/json'}\n",
    "\n",
    "\n",
    "ChipReplicationQualityMetrics = {\n",
    "    'reproducible_peaks', 'idr_cutoff', 'rescue_ratio', \n",
    "    'self_consistency_ratio', 'reproducibility'}\n",
    "\n",
    "ChipPeakEnrichmentQualityMetrics = {\n",
    "    'frip', 'min_size', '25_pct', '50_pct', '75_pct', 'max_size', 'mean'}\n",
    "\n",
    "ChipAlignmentEnrichmentQualityMetrics = {\n",
    "    'subsampled_reads', 'estimated_fragment_len', 'corr_estimated_fragment_len',\n",
    "    'phantom_peak', 'corr_phantom_peak', 'argmin_corr', 'min_corr', 'NSC', \n",
    "    'RSC', 'auc', 'syn_auc', 'x_intercept', 'syn_x_intercept', 'elbow_pt', \n",
    "    'syn_elbow_pt', 'jsd', 'syn_jsd', 'pct_genome_enrich', 'diff_enrich', \n",
    "    'ch_div'}  \n",
    "\n",
    "ChipLibraryQualityMetrics = {\n",
    "    'unpaired_reads', 'paired_reads', 'unmapped_reads', \n",
    "    'unpaired_duplicate_reads', 'paired_duplicate_reads',\n",
    "    'paired_optical_duplicate_reads', 'pct_duplicate_reads', 'total_fragments', \n",
    "    'distinct_fragments', 'positions_with_one_read', 'NRF', 'PBC1', 'PBC2'}\n",
    "\n",
    "ChipAlignmentQualityMetrics = {\n",
    "    'processing_stage', 'total_reads', 'total_reads_qc_failed', \n",
    "    'duplicate_reads', 'duplicate_reads_qc_failed', 'mapped_reads', \n",
    "    'mapped_reads_qc_failed', 'pct_mapped_reads', 'paired_reads', \n",
    "    'paired_reads_qc_failed', 'read1', 'read1_qc_failed', 'read2', \n",
    "    'read2_qc_failed', 'properly_paired_reads', \n",
    "    'properly_paired_reads_qc_failed', 'pct_properly_paired_reads', \n",
    "    'with_itself', 'with_itself_qc_failed', 'singletons', \n",
    "    'singletons_qc_failed', 'pct_singletons', 'diff_chroms', \n",
    "    'diff_chroms_qc_failed'}\n",
    "\n",
    "\n",
    "rows = []\n",
    "    \n",
    "\n",
    "def get_metadata_for_experiment(exp_accession_id):\n",
    "    \"\"\"Returns how many numbers lie within `maximum` and `minimum` in a given `row`\"\"\"\n",
    "    accession_id = 'NNNN'\n",
    "    \n",
    "    search_url = \"https://www.encodeproject.org/experiments/{}/?format=json\".format(\n",
    "        exp_accession_id)\n",
    "    json_results = requests.get(search_url, headers=HEADERS, \n",
    "                                auth=encode_auth).json()\n",
    "    assembly = ''\n",
    "\n",
    "    fastqs = []\n",
    "    fastqs_run_type = []\n",
    "    assay_type = []\n",
    "\n",
    "    alignments = [] \n",
    "    alignments_download_urls = []\n",
    "    alignments_md5sums = []\n",
    "    alignments_qc_metrics = []\n",
    "\n",
    "    unfiltered_alignments = []\n",
    "    unfiltered_alignments_download_urls = []\n",
    "    unfiltered_alignments_md5sums = []\n",
    "    unfiltered_alignments_qc_metrics = []\n",
    "\n",
    "    preferred_default_bed_narrowPeak = []\n",
    "    preferred_default_bed_narrowPeak_download_urls = []\n",
    "    preferred_default_bed_narrowPeak_md5sums = []\n",
    "    preferred_default_bed_narrowPeak_qc_metrics = []\n",
    "    \n",
    "    number_of_peaks = []\n",
    "\n",
    "    encode4_files = []\n",
    "    \n",
    "    try:\n",
    "        json_results['analyses']\n",
    "        \n",
    "    except:\n",
    "        print(f\"une problem with for {exp_accession_id}\")\n",
    "        return\n",
    "        \n",
    "    encode4_files = [] \n",
    "    for analysis_object in json_results['analyses']:\n",
    "        if 'ENCODE4' in analysis_object['pipeline_award_rfas']:\n",
    "            encode4_files.extend([f.split('/')[2] for f in \\\n",
    "                              analysis_object['files']])\n",
    "    \n",
    "\n",
    "    for file_dict in json_results['files']:\n",
    "        if file_dict['file_type'] == 'fastq': \n",
    "            fastqs.append(file_dict['accession'])\n",
    "            fastqs_run_type.append(file_dict['run_type'])\n",
    "            continue\n",
    "\n",
    "        if file_dict['accession'] not in encode4_files:\n",
    "            #print(file_dict['accession'], encode4_files)\n",
    "            #print(\"Skipping\", file_dict['accession'])\n",
    "            continue\n",
    "\n",
    "        # fastq files dont have 'assembly' so we ^^^ check\n",
    "        # that first\n",
    "        # this check may not be necessary because we are \n",
    "        # checking for ENCODE4\n",
    "        if file_dict['status'] == 'archived' or \\\n",
    "            file_dict['assembly'] == 'hg19':\n",
    "            continue\n",
    "\n",
    "        # this will get overwritten several times for each \n",
    "        # file, but it's ok \n",
    "        assembly = file_dict['assembly']\n",
    "        assay_type=file_dict[\"assay_title\"]\n",
    "\n",
    "        if file_dict['file_type'] == 'bed narrowPeak' and \\\n",
    "            'preferred_default' in file_dict.keys() and \\\n",
    "            file_dict['preferred_default']:\n",
    "\n",
    "            download_url = \"https://www.encodeproject.org/\" + \\\n",
    "               \"files/{}/@@download/{}.bed.gz\".format(\n",
    "                   file_dict['accession'], \n",
    "                   file_dict['accession'])\n",
    "\n",
    "            preferred_default_bed_narrowPeak.append(\n",
    "                file_dict['accession'])\n",
    "            preferred_default_bed_narrowPeak_download_urls.append(\n",
    "                download_url)\n",
    "            preferred_default_bed_narrowPeak_md5sums.append(\n",
    "                file_dict['md5sum'])\n",
    "\n",
    "            _qc_metrics = {}\n",
    "            for qc_metrics in file_dict['quality_metrics']:\n",
    "                if qc_metrics['@type'][0] == \\\n",
    "                    'ChipReplicationQualityMetric':\n",
    "                    _qc_metrics['ChipReplicationQualityMetric'] = \\\n",
    "                        {k: qc_metrics[k] for k in \\\n",
    "                         qc_metrics.keys() & \\\n",
    "                         ChipReplicationQualityMetrics}\n",
    "\n",
    "                if qc_metrics['@type'][0] == \\\n",
    "                    'ChipPeakEnrichmentQualityMetric':\n",
    "                    _qc_metrics['ChipPeakEnrichmentQualityMetric'] = \\\n",
    "                        {k: qc_metrics[k] for k in \\\n",
    "                         qc_metrics.keys() & \\\n",
    "                         ChipPeakEnrichmentQualityMetrics}\n",
    "\n",
    "            preferred_default_bed_narrowPeak_qc_metrics.append(\n",
    "                _qc_metrics)\n",
    "            \n",
    "#             if 'reproducible_peaks' in file_dict['quality_metrics'][0]:\n",
    "#                 number_of_peaks.append(file_dict['quality_metrics'][0]['reproducible_peaks'])\n",
    "#             else:\n",
    "#                 number_of_peaks.append(file_dict['quality_metrics'][1]['reproducible_peaks'])\n",
    "            \n",
    "            continue\n",
    "\n",
    "        if file_dict['file_type'] == 'bam': \n",
    "\n",
    "            download_url = \"https://www.encodeproject.org/\" + \\\n",
    "                           \"files/{}/@@download/{}.bam\".format(\n",
    "                               file_dict['accession'], \n",
    "                               file_dict['accession'])\n",
    "\n",
    "            _qc_metrics = {}\n",
    "            for qc_metrics in file_dict['quality_metrics']:\n",
    "                if qc_metrics['@type'][0] == \\\n",
    "                    'ChipAlignmentEnrichmentQualityMetric':\n",
    "                    _qc_metrics['ChipAlignmentEnrichmentQualityMetric'] = \\\n",
    "                        {k: qc_metrics[k] for k in \\\n",
    "                         qc_metrics.keys() & \\\n",
    "                         ChipAlignmentEnrichmentQualityMetrics}\n",
    "\n",
    "                if qc_metrics['@type'][0] == \\\n",
    "                    'ChipLibraryQualityMetric':\n",
    "                    _qc_metrics['ChipLibraryQualityMetric'] = \\\n",
    "                        {k: qc_metrics[k] for k in \\\n",
    "                         qc_metrics.keys() & \\\n",
    "                         ChipLibraryQualityMetrics}\n",
    "\n",
    "                if qc_metrics['@type'][0] == \\\n",
    "                    'ChipAlignmentQualityMetric':\n",
    "                    _qc_metrics['ChipAlignmentQualityMetric'] = \\\n",
    "                        {k: qc_metrics[k] for k in \\\n",
    "                         qc_metrics.keys() & \\\n",
    "                         ChipAlignmentQualityMetrics}\n",
    "\n",
    "            if file_dict['output_type'] == 'unfiltered alignments':\n",
    "                unfiltered_alignments.append(file_dict['accession'])  \n",
    "                unfiltered_alignments_download_urls.append(download_url)\n",
    "                unfiltered_alignments_md5sums.append(file_dict['md5sum'])\n",
    "                unfiltered_alignments_qc_metrics.append(_qc_metrics)\n",
    "\n",
    "            if file_dict['output_type'] == 'alignments':\n",
    "                alignments.append(file_dict['accession'])  \n",
    "                alignments_download_urls.append(download_url)\n",
    "                alignments_md5sums.append(file_dict['md5sum'])\n",
    "                alignments_qc_metrics.append(_qc_metrics)    \n",
    "\n",
    "    row = [accession_id, assay_type, exp_accession_id, fastqs, fastqs_run_type,\n",
    "           assembly, preferred_default_bed_narrowPeak, \n",
    "           preferred_default_bed_narrowPeak_download_urls, \n",
    "           preferred_default_bed_narrowPeak_md5sums, \n",
    "           preferred_default_bed_narrowPeak_qc_metrics,\n",
    "           unfiltered_alignments, unfiltered_alignments_download_urls,\n",
    "           unfiltered_alignments_md5sums, \n",
    "           unfiltered_alignments_qc_metrics, alignments, \n",
    "           alignments_download_urls, alignments_md5sums, \n",
    "           alignments_qc_metrics]\n",
    "\n",
    "    #print(row)\n",
    "\n",
    "    unique_run_types = set(fastqs_run_type)\n",
    "    if len(unique_run_types) > 1:\n",
    "        print(accession_id, exp_accession_id, \"run_types\", \n",
    "              len(unique_run_types), \"****** MULTIPLE RUN TYPES ******\")\n",
    "        \n",
    "    return (row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8b337ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNNN ENCSR385SZQ run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR752EPH run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR000EQB run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR000EPV run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR000ENI run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR000EPG run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR000EQC run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR000EQI run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR000EPD run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR000EQD run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR000EQG run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR000EQF run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR000EPE run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR000EQJ run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR000ENS run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR000ELW run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR000EOD run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR000FDI run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR000FJH run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR582IPV run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR083STA run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR475VQD run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR097BWW run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR771DAX run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR595CSH run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR621ENC run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR015BGH run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR515EWI run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR474GZQ run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR782XFY run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR627NIF run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR503HIB run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR346IHH run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR269SIA run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR301OGM run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR829MXU run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR000FJL run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR000FEK run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR946MVP run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR127PWK run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR691MQJ run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR426IEA run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR548MMD run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR678ILN run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR167JFX run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR774RCO run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR662HMO run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR845CFB run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR768OLL run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR594NOE run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR706IDL run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR937UWI run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR493VDS run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR931UQB run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR098PTC run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR325LYJ run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR383BLX run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR855FOP run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR257BGZ run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR035RVH run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR217RVH run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR316UDN run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR035QHH run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR224IYD run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR622TWS run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR228VNQ run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR770DEN run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR184LMY run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR683QJJ run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR731QLJ run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR620WAR run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR434OBM run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR452DCM run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR020LUD run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR789VGQ run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR381PXW run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR000EOO run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR426TPQ run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR000EOT run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR000FFJ run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR704HNG run_types 2 ****** MULTIPLE RUN TYPES ******\n",
      "NNNN ENCSR468ZXN run_types 2 ****** MULTIPLE RUN TYPES ******\n"
     ]
    }
   ],
   "source": [
    "# import multiprocessing as mp\n",
    "\n",
    "#  # Step 1: Init multiprocessing.Pool()\n",
    "# pool = mp.Pool(40)\n",
    "#  # Step 2: `pool.apply` the `howmany_within_range()`\n",
    "# results = pool.map(get_metadata_for_experiment, experiments)\n",
    "#  # Step 3: Don't forget to close\n",
    "# pool.close() \n",
    "results = [get_metadata_for_experiment(exp_accession_id=id) for id in experiments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c85d39a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_results = [i for i in results if type(i)==type([])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c41982e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(filtered_results) \n",
    "columns = ['experiment_series','assay_type' ,'experiment', 'fastqs', 'fastqs_run_type', \n",
    "       'assembly', 'preferred_default_bed_narrowPeak', \n",
    "       'preferred_default_bed_narrowPeak_download_urls', \n",
    "       'preferred_default_bed_narrowPeak_md5sums',\n",
    "       'preferred_default_bed_narrowPeak_qc_metrics', \n",
    "       'unfiltered_alignments', 'unfiltered_alignments_download_urls', \n",
    "       'unfiltered_alignments_md5sums', 'unfiltered_alignments_qc_metrics',\n",
    "       'alignments', 'alignments_download_urls', 'alignments_md5sums', \n",
    "       'alignments_qc_metrics']\n",
    "df.to_csv('metadata_'+dintype+'.tsv', \n",
    "           sep='\\t', index=False, header=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ac86c436",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('metadata_'+dintype+'.tsv', \n",
    "                            sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7ffa800d",
   "metadata": {},
   "outputs": [],
   "source": [
    "alignments_urls = []\n",
    "alignments_md5sums = []\n",
    "unfiltered_alignments_urls = []\n",
    "unfiltered_alignments_md5sums = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    unfiltered_alignments_urls.extend(row['unfiltered_alignments_download_urls'])\n",
    "    unfiltered_alignments_md5sums.extend(row['unfiltered_alignments_md5sums'])\n",
    "    \n",
    "    alignments_urls.extend(row['alignments_download_urls'])\n",
    "    alignments_md5sums.extend(row['alignments_md5sums'])\n",
    "    \n",
    "\n",
    "alignments_urls_md5sums = ([list(a) for a in zip(alignments_urls, alignments_md5sums)])\n",
    "alignments_urls_md5sums_df = pd.DataFrame(alignments_urls_md5sums)\n",
    "alignments_urls_md5sums_df.to_csv('alignments_bams_urls_md5sums'+dintype+'.txt', header=None, index=False, sep=' ')\n",
    "\n",
    "unfiltered_alignments_urls_md5sums = ([list(a) for a in zip(unfiltered_alignments_urls, unfiltered_alignments_md5sums)])\n",
    "unfiltered_alignments_urls_md5sums_df = pd.DataFrame(unfiltered_alignments_urls_md5sums)\n",
    "unfiltered_alignments_urls_md5sums_df.to_csv('unfiltered_alignments_bams_urls_md5sums'+dintype+'.txt', header=None, index=False, sep=' ')\n",
    "\n",
    "# preferred default IDR thresholded peaks\n",
    "preferred_default_urls = []\n",
    "preferred_default_md5sums = []\n",
    "for idx, row in df.iterrows():\n",
    "    preferred_default_urls.extend(row['preferred_default_bed_narrowPeak_download_urls'])\n",
    "    preferred_default_md5sums.extend(row['preferred_default_bed_narrowPeak_md5sums'])\n",
    "\n",
    "preferred_default_urls_md5sums = ([list(a) for a in zip(preferred_default_urls, preferred_default_md5sums)])\n",
    "\n",
    "preferred_default_urls_md5sums_df = pd.DataFrame(preferred_default_urls_md5sums)\n",
    "preferred_default_urls_md5sums_df.to_csv('preferred_default_urls_md5sums'+dintype+'.txt', header=None, index=False, sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da191157",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
